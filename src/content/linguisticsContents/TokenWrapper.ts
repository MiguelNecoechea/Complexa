/**
 * Core utility responsible for inserting visual markup (<span class="lingua-token">)
 * around Japanese tokens that have already been segmented on the backend side.
 *
 * 1. The caller passes an ordered list of `Paragraph` objects and the parallel
 *    `Token[][]` (same length, one token array per paragraph).
 *
 * 2. `wrap()` iterates paragraph‑by‑paragraph, and inside each paragraph walks
 *    **every** DOM `Text` node (already collected by the extractor).
 *
 * 3. For each `Text` node we invoke `wrapTextNode()` which performs a sliding‑
 *    window scan, copying plain substrings and wrapping matching tokens with
 *    a <span> generated by `buildSpan()`.
 *
 * 4. We batch DOM mutations in a `DocumentFragment` and finally swap the
 *    original `Text` node with the fragment via `replaceChild()` – one reflow
 *    per node instead of per token (see MDN on `DocumentFragment`).
 *
 * 5. All <span> references are returned to the caller as a 2‑D matrix so that
 *    higher‑level UI code (colouring, tooltip positioning, etc.) can work with
 *    them later.
 */

import { Paragraph } from "../../models/Paragraph";
import { Token } from "../../models/JapaneseTokens";
import { FilterTokens } from "../../appFunctions/WordFilters/FilterTokens";
import HoverTokenView from "../../views/HoverTokenView";

export class TokenWrapper {
    private tooltipReady = false;

    constructor(private readonly tokenFilter = FilterTokens.instance) {}

    /**
     * Public entry point – wrap the whole page (or selection).
     *
     * @param paragraphs      Ordered list of `Paragraph`s returned by the
     *                        extraction phase.  Each paragraph exposes its
     *                        original container element and an *ordered* array
     *                        of `Text` nodes (`textNodes`).
     * @param tokenizedArrays A parallel array where `tokenizedArrays[i]` holds
     *                        the tokens for `paragraphs[i]`.
     * @returns               2‑D matrix: one row per paragraph, each containing
     *                        the <span> elements we created for that paragraph.
     */
    async wrap(
        paragraphs: Paragraph[],
        tokenizedArrays: Token[][],
    ): Promise<HTMLElement[][]> {
        const matrix: HTMLElement[][] = [];

        for (let pIdx = 0; pIdx < paragraphs.length; pIdx++) {
            const paragraph = paragraphs[pIdx];
            const tokens = tokenizedArrays[pIdx] ?? [];
            const row: HTMLElement[] = [];

            if (!tokens.length) {
                matrix.push(row);
                continue;
            }

            let tokIdx = 0;
            let paraOffset = 0;
            for (const node of paragraph.textNodes) {
                const { fragment, consumed } = this.wrapTextNode(
                    node,
                    tokens,
                    tokIdx,
                    paraOffset,
                    row,
                );
                node.parentNode!.replaceChild(fragment, node);
                tokIdx += consumed;
                paraOffset += node.data.length;
            }
            matrix.push(row);
        }

        await this.mountHoverToolTip();
        return matrix;
    }

    /**
     * Walk a single Text node from left→right, emit plain text + wrapped tokens,
     * and return how many tokens we consumed.
     *
     * @param node        The `Text` DOM node we’re processing.
     * @param tokens      Full token array for the paragraph.
     * @param startIdx    Index of the first *unwrapped* token.
     * @param paraOffset  Absolute paragraph offset of node.data[0].
     * @param row         Collects <span> references for caller.
     */
    private wrapTextNode(
        node: Text,
        tokens: Token[],
        startIdx: number,
        paraOffset: number,
        row: HTMLElement[],
    ): { fragment: DocumentFragment; consumed: number } {
        const frag = node.ownerDocument!.createDocumentFragment();
        const text = node.data;
        const nodeEnd = paraOffset + text.length;

        let localPos = 0;
        let idx = startIdx;

        while (idx < tokens.length && tokens[idx].offset < nodeEnd) {
            const tok = tokens[idx];
            const relStart = tok.offset - paraOffset;

            if (relStart > localPos) {
                frag.append(
                    node.ownerDocument!.createTextNode(
                        text.slice(localPos, relStart),
                    ),
                );
            }

            if (
                this.tokenFilter.shouldExclude(tok) ||
                tok.is_japanese == "false"
            ) {
                frag.append(node.ownerDocument!.createTextNode(tok.surface));
            } else {
                const span = this.buildSpan(tok);
                frag.append(span);
                row.push(span);
            }

            localPos = relStart + tok.surface.length;
            idx++;
        }

        if (localPos < text.length) {
            frag.append(
                node.ownerDocument!.createTextNode(text.slice(localPos)),
            );
        }

        return { fragment: frag, consumed: idx - startIdx };
    }

    /**
     * @private
     * Construct a <span> element populated with linguistic metadata so that the
     * hover UI and other modules can query it later.
     *
     * @param tok Token metadata from the backend (surface, reading, pos, ...).
     */
    private buildSpan(tok: Token): HTMLSpanElement {
        const span = document.createElement("span");
        span.textContent = tok.surface;
        span.classList.add("lingua-token", "mw-no-invert", "notheme");

        span.dataset.surface = tok.surface;
        span.dataset.pos = tok.pos;
        span.dataset.lemma = tok.lemma;
        span.dataset.tag = tok.tag;
        span.dataset.dep = tok.dep;
        span.dataset.head = String(tok.head);
        span.dataset.offset = String(tok.offset);
        span.dataset.ent_obj = tok.ent_iob;
        span.dataset.ent_type = tok.ent_type;
        span.dataset.is_japanese = tok.is_japanese;
        if (tok.reading) span.dataset.reading = tok.reading;

        return span;
    }

    /**
     * @private
     * Lazily inject the shared hover tooltip into the document exactly once.
     */
    private async mountHoverToolTip(): Promise<void> {
        if (this.tooltipReady) return;

        const hoverHTML = await fetch(
            chrome.runtime.getURL("static/views/hoverView.html"),
        ).then((r) => r.text());

        document.body.insertAdjacentHTML("beforeend", hoverHTML);
        new HoverTokenView();
        this.tooltipReady = true;
    }
}
